# -*- coding: utf-8 -*-
"""Untitled10.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ZsrlOIk6GAL3lHA_xXdT_8A2zYmJS863
"""

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.naive_bayes import MultinomialNB
from sklearn.pipeline import make_pipeline
import joblib
from nltk.sentiment import SentimentIntensityAnalyzer
import random

# Load data from CSV
df = pd.read_csv('train.csv', encoding='latin1')

# Handling missing values in the 'text' column
df['text'].fillna('', inplace=True)

# Assuming 'text' is the correct column name for user input
user_input_column_name = 'text'

# Assuming 'sentiment' is the correct column name for the target labels
target_column_name = 'sentiment'

# Split the data into training and testing sets
train_data, test_data = train_test_split(df, test_size=0.2, random_state=42)

# Create a model pipeline for training
model = make_pipeline(CountVectorizer(), MultinomialNB())
model.fit(train_data[user_input_column_name], train_data[target_column_name])

# Save the trained model to a file
joblib.dump(model, 'sentiment_model.joblib')

# Load the trained model
loaded_model = joblib.load('sentiment_model.joblib')

# Create a sentiment intensity analyzer
sid = SentimentIntensityAnalyzer()

# List of motivational advice and praise statements
motivational_advice = [
    "Tough times never last, but tough people do.",
    "Every cloud has a silver lining.",
    "Believe in yourself and all that you are.",
]

praise_statements = [
    "You're doing an amazing job!",
    "Your positive attitude is inspiring!",
    "Keep up the great work!",
]

# Function to analyze sentiment and provide advice or praise
def analyze_sentiment(user_input):
    # Use the VADER sentiment analyzer to get sentiment intensity scores
    sentiment_scores = sid.polarity_scores(user_input)

    # Determine sentiment based on compound score
    if sentiment_scores['compound'] >= 0.05:
        predicted_sentiment = 'positive'
    elif sentiment_scores['compound'] <= -0.05:
        predicted_sentiment = 'negative'
    else:
        predicted_sentiment = 'neutral'

    # Generate advice or praise
    if predicted_sentiment == 'negative':
        advice = random.choice(motivational_advice)
        return f"Analyzed Sentiment: {predicted_sentiment}\nMotivational Advice: {advice}"
    elif predicted_sentiment == 'positive':
        praise = random.choice(praise_statements)
        return f"Analyzed Sentiment: {predicted_sentiment}\nPraise: {praise}"
    else:
        return f"Analyzed Sentiment: {predicted_sentiment}\nNeutral sentiment detected."

# Real-time sentiment analysis loop
while True:
    user_input = input("Enter your text (or type 'exit' to end): ")

    if user_input.lower() == 'exit':
        break

    sentiment_analysis_result = analyze_sentiment(user_input)
    print(sentiment_analysis_result + "\n")

import pandas as pd
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.naive_bayes import MultinomialNB
from sklearn.pipeline import make_pipeline
import joblib

# Load data from CSV
df = pd.read_csv('train.csv', encoding='latin1')

# Handling missing values in the 'text' column
df['text'].fillna('', inplace=True)

# Assuming 'text' is the correct column name for user input
user_input_column_name = 'text'

# Assuming 'sentiment' is the correct column name for the target labels
target_column_name = 'sentiment'

# Split the data into training and testing sets
train_data, test_data = train_test_split(df, test_size=0.2, random_state=42)

# Create a model pipeline for training
model = make_pipeline(CountVectorizer(), MultinomialNB())
model.fit(train_data[user_input_column_name], train_data[target_column_name])

# Save the trained model to a file
joblib.dump(model, 'sentiment_model_agewise.joblib')

# Load the trained model
loaded_model_agewise = joblib.load('sentiment_model_agewise.joblib')

# Function to analyze sentiment for each age group
def analyze_sentiment_age_group(age_group):
    age_group_df = df[df['Age of User'] == age_group]
    user_input = age_group_df[user_input_column_name].values  # All texts for the age group
    predicted_sentiments = loaded_model_agewise.predict(user_input)
    return pd.DataFrame({'Age Group': [age_group]*len(predicted_sentiments), 'Sentiment': predicted_sentiments})

# Analyze sentiment for each age group
age_groups = df['Age of User'].unique()
results_age_group = pd.concat([analyze_sentiment_age_group(age_group) for age_group in age_groups], ignore_index=True)

# Count the number of positive and negative sentiments for each age group
sentiment_counts_age_group = results_age_group.groupby(['Age Group', 'Sentiment']).size().unstack().fillna(0)

# Find the age group with the most positive and most negative sentiments
most_positive_age_group = sentiment_counts_age_group['positive'].idxmax()
most_negative_age_group = sentiment_counts_age_group['negative'].idxmax()

# Print the results
print(f"Age Group with Most Positive Sentiment: {most_positive_age_group}")
print(f"Age Group with Most Negative Sentiment: {most_negative_age_group}")

# Plot the results as a line graph
fig, ax = plt.subplots(figsize=(12, 6))
sentiment_counts_age_group.plot(kind='line', marker='o', ax=ax)
ax.set_title('Age-wise Sentiment Analysis')
ax.set_xlabel('Age Group')
ax.set_ylabel('Count')
plt.legend(['Negative', 'Neutral', 'Positive'], title='Sentiment')
plt.show()

import pandas as pd
import matplotlib.pyplot as plt
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.naive_bayes import MultinomialNB
from sklearn.pipeline import make_pipeline
import joblib

# Load data from CSV
df = pd.read_csv('train.csv', encoding='latin1')

# Handling missing values in the 'text' column
df['text'].fillna('', inplace=True)

# Assuming 'text' is the correct column name for user input
user_input_column_name = 'text'

# Assuming 'sentiment' is the correct column name for the target labels
target_column_name = 'sentiment'

# Create a model pipeline for training
model = make_pipeline(CountVectorizer(), MultinomialNB())
model.fit(df[user_input_column_name], df[target_column_name])

# Save the trained model to a file
joblib.dump(model, 'sentiment_model_countrywise.joblib')

# Load the trained model
loaded_model_countrywise = joblib.load('sentiment_model_countrywise.joblib')

# Function to analyze sentiment for each country
def analyze_sentiment_country(country):
    country_df = df[df['Country'] == country]
    user_input = country_df[user_input_column_name].values  # All texts for the country
    predicted_sentiments = loaded_model_countrywise.predict(user_input)
    return pd.DataFrame({'Country': [country]*len(predicted_sentiments), 'Sentiment': predicted_sentiments})

# Analyze sentiment for each country
countries = df['Country'].unique()
results_country = pd.concat([analyze_sentiment_country(country) for country in countries], ignore_index=True)

# Count the number of positive and negative sentiments for each country
sentiment_counts = results_country.groupby(['Country', 'Sentiment']).size().unstack().fillna(0)

# Find the country with the most positive and most negative sentiments
most_positive_country = sentiment_counts['positive'].idxmax()
most_negative_country = sentiment_counts['negative'].idxmax()

# Print the results
print(f"Country with Most Positive Sentiment: {most_positive_country}")
print(f"Country with Most Negative Sentiment: {most_negative_country}")

# Plot the results as a line graph
fig, ax = plt.subplots(figsize=(12, 6))
sentiment_counts.plot(kind='line', marker='o', ax=ax)
ax.set_title('Country-wise Sentiment Analysis')
ax.set_xlabel('Country')
ax.set_ylabel('Count')
plt.legend(['Negative', 'Neutral', 'Positive'], title='Sentiment')
plt.show()